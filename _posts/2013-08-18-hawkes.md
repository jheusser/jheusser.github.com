---
layout: post
title: Bitcoin Trade Arrival as Self-Exciting Process
---

{{ page.title }}
================

<p class="meta">18 August 2013</p>

# Introduction

This article describes the potential application of Hawkes processes to trading Bitcoin. We show that the clustered arrival of Mtgox orders is well explained by such a self-exciting model. We also show how to fit the model to the data and evaluating its fit using R and Python.

# Self-excitability and clustering of order arrivals

Trades do not arrive in evenly spaced intervals but usually arrive clustered in time. Similarly the same trade sign tends to cluster together and result in a sequence of buy and sell orders. Various explanations for this are possible, such as algorithmic traders which split up their orders in smaller blocks, or for example trading systems that react to certain exchange messages.

The data we work with are 5000 trades between 13:10 and 19:57 on the 20 April 2013. Here is a plot of the trade counts aggregated over a 1 minute window.

<p>
<img src ="/images/trade_counts.png" alt="Intensity" align="center" title="Intensity" style="max-height: 700px; max-width: 700px;"></img>
</p>

The average trade count per minute is 13, however we can make out a couple of instances where it exceeds 50. Usually the higher trade intensity last a couple of minutes and then dies down again towards the mean. In particular, the 15 minutes or so after 16:00 we can see very high trading intensity with one instance of over 200 orders per minute, then a slow decrease of intensity over the next ~10 minutes.

The most basic way to describe arrival of event counts, such as the time series above, is a poisson process with one parameters \\(\lambda\\). In a poisson process the expected number of events per unit of time is defined by the one parameter. This is widely used as it fits well to a lot of scenarios such as arrival of telephone calls in a call centre [ref wikipedia]. For our purposes this is too simple as we need a way to explain the clustering and mean reversion.

Hawkes Processes, or also called self-exciting processes, are an extention of the basic poisson process which aim to explain such clustering. Such self-excitable models are very widely used in various sciences; some examples are seismology (modelling of earthquakes and volcanic eruptions), ecology (wildfire assessment [peng]), neuroscience (modelling of brain spike trains which bunch together [bouret]), even modelling of eruption of violence ([lewis] on modelling civilian deaths in Iraq, and [mohler] on crime forecasting), and naturally finance and trading (more to that in a section below).

Let's move on to understanding and fitting a Hawkes process to the data above.

# Hawkes Processes

A Hawkes process models the intensity, or event occurence rate of a process. It is an extension of a poisson process with the additional ability to explain event clustering.

An example realisation of a Hawkes process is plotted in the next figure.

<p>
<img src ="/images/fake_intensity.png" alt="Intensity" align="center" title="Intensity" style="max-height: 700px; max-width: 700px;"></img>
</p>

It consists of 8 events, which usually take the form of time stamps, indicated by the rug, and a sample intensity path which is defined by three parameters 

$$(\alpha, \beta, \mu) = (0.1, 1, 0.5)$$

Here, \\(\mu\\) is the base rate the process reverts to, \\(\alpha\\) is the intensity jump right after an event occurence, and \\(\beta\\) is the exponential intensity decay. The base rate can also be interpreted as the intensity of (to the process) exogenous events such as news. The other parameters \\(\alpha\\) and \\(\beta\\) define the clustering properties of the process, where it is usually the case that \\(\alpha \lt \beta\\) which ensures that the intensity decreases quicker than new events increase it -- otherwise the process would explode.

We can clearly see the self-excitability in that the first four events before the time mark 2 are close together which leads to a large peak of intensity by the fourth event as the previous three already increased the intensity rate. This demonstrates how occurence of multiple events with short durations between them causes an increased overall intensity rate. The fifth data point only arrives at time mark 4 which, in the meantime, lead to an exponential decrease of intensity.

The conditional intensity takes the form
<p>
$$\lambda(t) = \mu + \sum_{t_i \lt t} \alpha e^{-\beta (t-t_i)}$$
</p>
The exponential function defines the memory of the process, i.e. the way how past events affect the current event. Summation applies this function over the history of events \\(t_i\\) up to the current event \\(t\\).  

The parameters can be fitted using conventional Maximum Likelihood Estimation and a convex solver, or you can use an R package for it such as _ptproc_ [ptproc].


# Fitting Bitcoin Trade Arrival to a Hawkes Process

The intensity path is fully defined given a set of trade times \\(t_1 \lt t_2 \lt \cdots \lt t_n\\) which are unix timestamps in our case. Given this we can easily apply MLE using the _ptproc_ package. The following function fits the model given an initial guess of the parameters and constraints on the parameters being positive.

{% highlight python %}
fit_hawkes <- function(data) {
  # initial guess where a is alpha and C is beta
  pstart <- c(mu = 0.5, C = 1, a = 0.1)

  # create a ptproc object using the conditional intensity function as defined by ptproc
  ppm <- ptproc(pts = data, cond.int = hawkes.cond.int, params = pstart)

  # assumption that the intensity has to be positive
  condition(ppm) <- penalty(code = NULL, condition = quote(any(params < 0)))

  # fit using standard optim
  f <- ptproc.fit(ppm, optim.control = list(trace = 2), alpha = 1e+5, hessian = TRUE)

  return (f)
}
{% endhighlight %}

I evaluate the function defined above using the first 5000 timestamp of the trade_times dataframe (which I exported from Python). Another important aspect was to randomise timestamps of trades which occured within the same second. As the a set of ordered trade times is required every timestamp has to be unique. Some authors suggest to uniformly distribute timestamps within the same second by adding milliseconds to it, which is what I was using.

{% highlight python %}
> f <- fit_hawkes(trade_times[0:5000])
> summary(f)
Model name: HAWKES.COND.INT 

Fitted Parameter Values:
            mu               C               a  
0.070223167168  1.795900246884  1.182079921093  

Model AIC:	 13788.389497822
H. Pois. AIC:	 25836.993184719
{% endhighlight %}

We end up with the parameter estimates of \\(\mu = 0.07, \alpha = 1.18, \beta = 1.79\\). We can now evaluate the fitted intensity function over a grid of timestamps which range form the min to the max timestamp in our training set trade_times[0:5000]. 

To get an overlay of empirical and fitted intensity rates we integrate the instanteanous intensity over the same interval as the empirical dataframe. This leads to the following plot comparing empirical counts (from the first plot of this article) and the fitted intensities.

<p>
<img src ="/images/fitted_intensity.png" alt="Fitted Intensity" align="center" title="Fitted Intensity" style="max-height: 700px; max-width: 700px;"></img>
</p>

Well it's not bad, the magnitude of the fitted intensities are however off by about a factor of 5. This has most likely to do with the choice of scaling of the parameters during optimisation; the randomisation of timestamps within the same minute might also have an influence, as described in [filimonov] which beside other estimation biases describe timestamp grouping.

# Goodness of Fit

There's many ways of evaluating the goodness of fit. One is by comparing [AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion) values against a homogenous poisson model. As visible in the R summary above, our Hawkes model is a considerably better fit. 

Another way to test how well the model fits the data is by evaluating the residuals (which are kind of hard to obtain for a Hawkes process, thankfully _ptproc_ does the job). Theory says, if the model is a good fit, then the residual process should be homogenous and should have inter-event times (the difference between two residual event timestamps) which are exponentially distributed. A log-survivor plot of the interevent times confirms this. 
<p>
<img src ="/images/survival.png" alt="Survival" align="center" title="Survival" style="max-height: 700px; max-width: 700px;"></img>
</p>

Now that we know the model explains arrival clusters well, how can this be applied to trading? The next steps would be to at least consider the buy and sell arrivals individually and find a way to make predictions given a fitted Hawkes model. These intensity prediction can then form a part of a market making or directional strategy. But let us have a look at the literature to get some ideas.


# Application to Trading

[lorenzen] describes very clearly how to fit and evaluate Hawkes processes in a financial setting. Florenzen also treats the different ways of disambiguiating multiple trades in the same timestamp and evaluates the result on TAQ data.

In [hewlett] Hewlett predicts the future imbalance of buy and sell trades using a bivariate self- and cross-excitation process between buy and sell arrivals. From a price impact formula derived from this imbalance the author devises an optimal liquidation strategy.

In [carlsson] the authors use the buy and sell intensity ratio of a bivariate hawkes process as entry signal to place a directional trade.

In [cartea] the authors develop a high frequency market making strategy which distinguishes between influential and non-influential trades as a way to get a better fit of their hawkes model to the data (I assume). A further ingredient in the model is a short-term midprice drift which allows to place directional bets and avoids some adverse selection. 
Their placement of bid and ask quotes then depends on the combination of the short-term drift, order imbalance (asymmetric arrivals of buy and sell) and inventory mean reversion.


# Improvements 

The loglikelihood function of a Hawkes process has to iterate through the whole history of trades for every set of parameters. This is very expensive and leads to a fitting time of 12 minutes for 5000 trades on my macbook pro. There is a recursive formulation for the likelihood which memoises the calls and speeds up evaluation [ref]. This is still inefficient and especially for high frequency trading purposes fast fitting procedures are of interest. 

While one does not know what is actually used by HFT practicioners some recent research from this year shows a way to calculate the intensity rate using GPU [gpu], which clearly shows there is interest to have very fast Hawkes calibration.

Some even more recent research, published last month, by Fonseca and Zaatour describes an even more efficient way to calibrate a Hawkes process. Instead of MLE they use Generalised Method of Moments to estimate parameter values. While not as accurate as MLE, the GMM method using an empirical and analytical autocorrelation ..... [xxxxxxxx]

# Conclusion

[tbw]



# References

[gpu] C. Guo and W. Luk, E. Vinkovskaya, and R. Cont: Customisable Pipelined Engine for Intensity Evaluation in Multivariate Hawkes Point Processes.

[fonseca] J. Fonseca, and R. Zaatour: Hawkes Process: Fast Calibration, Application to Trade Clustering and Diffusive Limit. http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2294112.

[hewlett] P. Hewlett: Clustering of order arrivals, price impact and trade path optimisation.

[carlsson] J. Carlsson, M. Foo, H. Lee, H. Shek: High Frequency Trade Prediction with Bivariate Hawkes Process.

[lorenzen] F. Lorenzen: Analysis of Order Clustering Using High Frequency Data: A Point Process Approach

[lewis] E. Lewis, G. Mohler, P. Brantingham, and A. Bertozzi: Self-Exciting Point Process Models of Civilian Deaths in Iraq

[bouret] P. Reynaud-Bouret, C. Tuleau-Malot, V, Rivoirard, and F. Grammont: Spike trains as (in)homogeneous Poisson processes or Hawkes processes: non-parametric adaptive estimation and goodness-of-fit tests.  

[peng] R.D. Peng: Applications of Multi-dimensional Point Process Methodology to Wildfire Hazard Assessment.

[mohler] G.O. Mohler, M.B. Short, P.J. Brantingham, F.P. Schoenberg, and G.E. Tita: Self-Exciting Point Process Modeling of Crime

[ptproc] R.D. Peng: Multi-dimensional Point Process Models in R

[filimonov] V. Filimonov, and D. Sornette: Apparent criticality and calibration issues in the Hawkes self-excited point process model: application to high-frequency Ô¨Ånancial data. http://arxiv.org/abs/1308.6756
